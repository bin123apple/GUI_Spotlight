import io
import time
import base64
import random
from PIL import Image
from copy import deepcopy
from datasets import Dataset
from pydantic import BaseModel
from abc import abstractmethod
from vllm import LLM, SamplingParams
from concurrent.futures import ThreadPoolExecutor
from spotlight.tools_envs.environment import Environment
from typing import List, Dict, Sequence, Any, Union

class MultiTurnEnv(Environment):
    def __init__(self,
                 dataset: Dataset | None = None,
                 eval_dataset: Dataset | None = None,
                 few_shot: List[Dict[str, str]] = [],
                 sampling_args: Dict[str, Any] = {},
                 mask_env_response: bool = True,
                 max_workers: int = 10,
                 max_steps: int = 10,
                 sleep_time: float = 1.0,
                 **kwargs):
        super().__init__(**kwargs)
        self.few_shot = few_shot
        self.dataset = dataset
        self.eval_dataset = eval_dataset
        self.sampling_args = {
            "skip_special_tokens": False,
            "spaces_between_special_tokens": False,
            "n": 1
        }
        self.sampling_args.update(sampling_args)
        self.env_mask = 0 if mask_env_response else 1
        self.max_workers = max_workers
        self.sleep_time = sleep_time
        self.max_steps = max_steps

    @abstractmethod
    def is_completed(self, messages: List[dict[str, Union[str, List[dict]]]], **kwargs: Any) -> bool:
        pass

    @abstractmethod
    def env_response(self, messages: List[dict[str, Union[str, List[dict]]]], **kwargs: Any) -> Dict[str, str]:
        pass

    def step(self,
             states: List[Dict[str, Any]],
             llm: LLM,
             sampling_params: SamplingParams) -> List[Dict[str, Any]]:
        
        live_indices = [i for i, s in enumerate(states) if not s["completed"]]
        messages_to_step = [states[i]["messages"] for i in live_indices]
        llm_responses = llm.chat(messages_to_step, sampling_params=sampling_params, use_tqdm=True) # type: ignore
        
        def update_state(j, llm_response):
            """
            Update three things in the state:
            1. messages: append the assistant response
            2. all_prompts: include the prompt token ids and the assistant response text from all turns
            3. images: append the image from the tools if it exists
            """
            # sleep for 0-1 seconds to avoid rate limiting
            time.sleep(self.sleep_time * random.random())
            state = deepcopy(states[j])
            
            # Avoid image padding in the response
            # OtherWise there is some chance that the ERROR: 
            # num_image_tokens = image_grid_thw[index].prod() // merge_length IndexError: will happen
            clean_text = llm_response.outputs[0].text.replace('<|image_pad|>', '')
            state["messages"].append({"role": "assistant", "content": [{'type': 'text', 'text': clean_text}]})
        
            # Finish or execute the tools
            current_id_length = len(llm_response.prompt_token_ids) + len(llm_response.outputs[0].token_ids)
            if self.is_completed(state["messages"]) or current_id_length > sampling_params.max_tokens - 1:
                state["completed"] = True
                state['all_prompts'] = llm_response.prompt + clean_text + '<|im_end|>' # update all_prompts
            else:
                self.env_response(state["messages"], state["images"], state["images_offset"]) # call tools and add environment response

            return j, state

        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            results = list(executor.map(
                lambda args: update_state(*args),
                [(j, llm_responses[i]) for i, j in enumerate(live_indices)]
            ))

        for j, state in results:
            states[j] = state

        return states

    def generate(self, prompts: List[List[Dict[str, Any]]],
                 llm: LLM,
                 sampling_params: SamplingParams,
                 **kwargs: Any) -> Dict[str, List[Sequence[int]] | List[str] |  List[List[Dict[str, Any]]]]:
        
        """
        Generate responses for multiple prompts using the LLM and sampling parameters.
        Args:
            prompts: List of prompts, each a list of message dicts
            llm: LLM instance for generating responses
            sampling_params: Sampling parameters for the generation
            **kwargs: Additional arguments (not used here)
        Returns:
            A dictionary containing:
            - all_prompts: List of all prompts generated by the LLM
            - images: List of images generated by the tools, if any
        """
        custom_sp = sampling_params.clone()
        for k, v in self.sampling_args.items():
            setattr(custom_sp, k, v)

        def bs64_image(messages) -> str:
            image_entry = next(item for item in messages[0]["content"] if item["type"] == "image_url")
            data_uri = image_entry["image_url"]["url"]
            bs64_str = data_uri.split(",", 1)[1]
            image_bytes = base64.b64decode(bs64_str)
            img = Image.open(io.BytesIO(image_bytes)).convert("RGB")
            return img
        
        # initialize state variables
        all_completed = False
        states = []
        for m in prompts:
            img = bs64_image(m)
            state = {
                "messages": m,
                "all_prompts": "",
                "completed": False,
                "images": [img],
                "images_offset": [(0,0)],  # Store additional image info if needed
            }
            states.append(state)
        
        # main loop
        while not all_completed:
            states = self.step(states, llm, custom_sp)
            all_completed = all(state["completed"] for state in states)
            
        all_prompts = [s["all_prompts"] for s in states]
        all_images = [s["images"] for s in states] # list[list[Image.Image]] 
        all_messages = [s["messages"] for s in states]
        all_images_offset = [s["images_offset"] for s in states] # list[list[Tuple[int, int]]] 
        
        output = {
            "all_prompts": all_prompts,
            "images": all_images,
            "all_messages": all_messages,
            "images_offset": all_images_offset,
        }
        return output

    